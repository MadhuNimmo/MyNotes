## Machine Learning

# Lesson 1

* ML is about building intelligent artifacts that learn overtime based on experience and also, the science, the math and the engineering behind it.
* Supervised Learning is taking labelled datasets and gleaning infomartion so that you can label new datasets.
* Unsupervised Learning is about deriving common patterns from the data available by looking at the relationships. 
* Reinforcement learning is learning from delayed rewards through interaction with the environment.
* Fundamental problem behind ML is generalization, in particular inductive bias.
* Most of ML is about induction i.e. creating a general rule from example (specifics to generalities) or generalization 
  as opposed to deduction i.e. going from general rules to specific instances or reasoning.
|---------------------------------------------------------------|
| Supervised Learning    |         Function Approximation       |
|---------------------------------------------------------------|
| Unsupervised Learning  |          Function Description        |
|---------------------------------------------------------------|
| Reinforcement Learning | Learning Actions via Trial and Error |
|---------------------------------------------------------------|

# Lesson 2

* Supervised Learning can be majorly calssified into Classification and Regression
* Classification is about mapping inputs to discreete labels where as Regression is more about continuous value function.
* Calssification Learning
  - Instances : Inputs (pixels, discrete values)
  - Concept : Functions or Mapping of input to output , Notions 
  - Target Concept : Answer or What we are trying to find , Derived Notions
  - Hypothesis : Set of all concepts we want to entertain
  - Sample : Training Set, the pairings available
  - Candidate : Concept that may be the Target Concept
  - Testing Set : The set of data on which we try the Candidate concept to determine if it is the Target 
* Decision Trees 
  - Representaed as Tree
  - Like IF-ELSE statements
  - Deeper the tree, more complex it is
* ID3 - Top Down Approach to induce a DT
  - Information gain - the mathematical way to capture the amount of infomation
  that one gains by picking a particular attribute/ the reduction in randomness 
  Entropy - Measure of randomness. A coin has zero bits of entory, beacuse we know for sure the probabaility of the outcome. But if I have more of one label than 
  other  Summation{v} (P(v)logP(v)) Likelihood of already knowing what you are going to get. The goal is to choose the attribute for maximum gain.
  Gain(S,A) = Entropy(S) - Average Entropy that we have over a set of examples with a particular value. 
  An attribute may have. abunch of values like short/tall which is represented by 'v'.
  - Bias - 
  Algorithms that are searching thru space mostly have 2 kinds of biases:
      Restriction Bias: Hypothesis set that we actually care about. Like we only want to consider all Decision Trees here and no other representation.
      Preference Bias: What source of hypothesis from this heypothesis do we prefer? Heart of inductive bias
  Inductive Bias: 
      Given two decision trees that are both correct , ID3 would prefer the one that had a better split near the top. Also, it pefers the correct over incorrect trees.
      Which results in it prefering shorter trees to longer trees.
* Other considerations : Continous attributes are difficult to represent. There may be noise in the data. Can we completely trust the training data? 
  We can not entertain overfitting? To avoid overfitting, cross verify. Create a validation set may be. We can do pruning and see if it creates errors in the validation
  set. There may be problem of regression , which raises the question of splitting, needs voting.

# Lesson 3

* Regression - Mapping continuous imputs to outputs.
  We assume that their is a linear relationship. So, we try to find the best linear function that best captures the relationship between x-axis and y-axis variables.
  We find a line that minimizes the squared deviation from the actual point on the axis to the imaginary linear function line.
  Best fit line = least squared error. We do this through calculus.
  The idea is to reduce the sum of squared error (best loss error). The mean of all the Ys reduces the squared error.
  With more degrees of freedom or polynomial, we fit the error better. If the polynomial fits the training data too much, its kind of an overkill and may not perform well during testing.
  The goal is to generalize. Cross Validation is the key. Split the training data into folds.
  Train on n-1 chucnks and check 1 changing the folds everytime and find the average error, and go forward with the lowest error.
  best constant in terms of squared error is the mean

# Lesson 4

* Neural Networks - We sum up the inputs and their weights to find the actuvation values and compare it with the firing threshold of the 
  neural net unit. If it is yes, the output is 1 else 0. This type of neural unit is called perceptron. 
  What can they compute? It computes a half plane a linear function that clearly separates out the yes and no possibilities
  Perceptron Training - Given examples , find weights that map inputs to outputs  - perception rule(threshold) , gradient descent/delta rule(unthreshold)
  - Perception Rule - if the output is already correct for a certain input , then there is no change to the weights,
  where as if the putput is wrong, we will use the learning rate and the difference between the actual and estimated output to bring 
  the weight change. figure out the diff between the actual and extimated and move towards the direction in small steps/
  if you can separate the positives and the negatives by a half plane we say that its linearly separable.
  -Gradient Descent - 
  

