## Machine Learning

# Lesson 1

* ML is about building intelligent artifacts that learn overtime based on experience and also, the science, the math and the engineering behind it.
* Supervised Learning is taking labelled datasets and gleaning infomartion so that you can label new datasets.
* Unsupervised Learning is about deriving common patterns from the data available by looking at the relationships. 
* Reinforcement learning is learning from delayed rewards through interaction with the environment.
* Fundamental problem behind ML is generalization, in particular inductive bias.
* Most of ML is about induction i.e. creating a general rule from example (specifics to generalities) or generalization 
  as opposed to deduction i.e. going from general rules to specific instances or reasoning.
|---------------------------------------------------------------|
| Supervised Learning    |         Function Approximation       |
|---------------------------------------------------------------|
| Unsupervised Learning  |          Function Description        |
|---------------------------------------------------------------|
| Reinforcement Learning | Learning Actions via Trial and Error |
|---------------------------------------------------------------|

# Lesson 2

* Supervised Learning can be majorly calssified into Classification and Regression
* Classification is about mapping inputs to discreete labels where as Regression is more about continuous value function.
* Calssification Learning
  - Instances : Inputs (pixels, discrete values)
  - Concept : Functions or Mapping of input to output , Notions 
  - Target Concept : Answer or What we are trying to find , Derived Notions
  - Hypothesis : Set of all concepts we want to entertain
  - Sample : Training Set, the pairings available
  - Candidate : Concept that may be the Target Concept
  - Testing Set : The set of data on which we try the Candidate concept to determine if it is the Target 
* Decision Trees 
  - Representaed as Tree
  - Like IF-ELSE statements
  - Deeper the tree, more complex it is
* ID3
  - Information gain - the mathematical way to capture the amount of infomation
  that one gains by picking a particular attribute/ the reduction in randomness 
  $$
  Gain(S,A) = Entropy(S) - \sum_{i = 1}^{n}{(\bar{\frac{-b \pm \sqrt{b^2 - 4ac}}{2a}} - x_i)^2}
  $$
  

